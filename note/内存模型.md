#引言  
应用程序访问任意数据或运行任意代码往往遵循局部性原则，有两种不同类型的局部性：  
-时间局部性  时间局部性认为如果一个数据位置被引用，那么该数据在较短的时间周期内很可能会再次被引用，随着时间流逝，该数据被引用的可能性逐渐降低。  
-空间局部性  空间局部性认为如果一个内存位置被引用，则附近的位置也可能会被引用。  

cpu和gpu内存模型区别：  
-结构都使用相似的准则和模型  
![image](https://github.com/wustjie/cuda/assets/34996802/69b8ee7d-d99c-4d11-8426-5ff4d360aa89)  

-CUDA编程模型能将内存层次结构更好地呈现给用户，能让我们显式地控制它的行为。

#CUDA内存模型  
CPU内存层次结构中，一级缓存和二级缓存都是不可编程的存储器。CUDA内存模型提出了多种可编程内存的类型：  
·寄存器  
·共享内存  
·本地内存   
·常量内存  
·纹理内存  
·全局内存  
线程都有自己私有的本地内存。线程块有自己的共享内存，对同一线程块中所有线程都可见，其内容持续线程块的整个生命周期。  
所有线程都可以访问全局内存。所有线程都能访问的只读内存空间有：常量内存空间和纹理内存空间。  
![image](https://github.com/wustjie/cuda/assets/34996802/87e84522-5414-43ea-b872-27e878769438)  

##寄存器
寄存器变量对于每个线程来说都是私有的。  
Fermi GPU中，每个线程限制最多拥有63个寄存器。Kepler GPU将该限制扩展至每个线程可拥有255个寄存器。  
使用nvcc指令 -Xptxas -v,-abi=no 检查核函数使用硬件资源情况。  
如果使用寄存器数量超出，则会用本地内存替代，会导致性能的下降。  
编译器使用启发式策略来最小化寄存器的使用，以避免寄存器溢出。也可以在代码中为每个核函数显式地加上额外的信息来帮助编译器进行优化  
![image](https://github.com/wustjie/cuda/assets/34996802/a892b817-141e-41e2-b85c-839f51251fa6)  
