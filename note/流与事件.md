#CUDA流

CUDA中有两个级别的并发：内核级并发和网格级并发。  
内核级并发是用多个GPU线程去并发地完成一个内核任务。  
网格级并发则是把一个任务分解为多个内核任务。 CUDA流用于实现网格级的并发  

CUDA流是一系列异步的CUDA操作，这些操作按照主机代码确定的顺序在设备上执行。这些操作包括在主机与设备间进行数据传输，内核启动以及大多数由主机发起但由设备处理的其他命令。  
流中操作的执行相对于主机总是异步的。CUDA运行时决定何时可以在设备上执行操作。我们的任务是使用CUDA的API来确保一个异步操作在运行结果被使用之前可以完成。  

CUDA编程的一个典型流程是：  
1.将输入数据从主机移到设备上。  
2.在设备上执行一个内核。  
3.将结果从设备移回主机中。  
通常执行内核比传输数据耗时更多，通过将内核执行和数据传输调度到不同的流中，这些操作可以重叠，程序的总运行时间将被缩短。流在CUDA的API调用粒度上可实现流水线或双缓冲技术。  
![image](https://github.com/wustjie/cuda/assets/34996802/10f0e654-c7f6-4cef-aa1a-9cb6a540cc50)  
声明和创建一个显式流：  
cudaStream_t stream;  
cudaStreamCreate(&stream);  
销毁一个流则可以用：  
cudaError_t cudaStreamDestroy(cudaStream_t stream);  

CUDA的API函数一般可以分为同步或异步。具有同步行为的函数会阻塞主机端线程，直到它们完成。具有异步行为的函数被调用后，会立即将控制权归还给主机。  
异步函数和流是在CUDA中构建网格级并发的两个基本支柱。  

所有的CUDA操作（包括内核和数据传输）都在一个流中显式或隐式地运行。流分为两种类型：  
·隐式声明的流（空流）  
·显式声明的流（非空流）  
非空流可以被显式地创建和管理。如果想要重叠不同的CUDA操作，必须使用非空流。  

显式流中的操作必须是异步的，cudaMemcpy函数是一种同步操作，必须使用它的异步版本才能在显式流中进行数据拷贝  
cudaError_t cudaMemcpyAsync(void* dst, const void* src, size_t count, cudaMemcpyKind kind, cudaStream_t stream = 0);  



#CUDA事件  
