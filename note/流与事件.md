#CUDA流

CUDA中有两个级别的并发：内核级并发和网格级并发。  
内核级并发是用多个GPU线程去并发地完成一个内核任务。  
网格级并发则是把一个任务分解为多个内核任务。 CUDA流用于实现网格级的并发  

CUDA流是一系列异步的CUDA操作，这些操作按照主机代码确定的顺序在设备上执行。这些操作包括在主机与设备间进行数据传输，内核启动以及大多数由主机发起但由设备处理的其他命令。  
流中操作的执行相对于主机总是异步的。CUDA运行时决定何时可以在设备上执行操作。我们的任务是使用CUDA的API来确保一个异步操作在运行结果被使用之前可以完成。  

CUDA编程的一个典型流程是：  
1.将输入数据从主机移到设备上。  
2.在设备上执行一个内核。  
3.将结果从设备移回主机中。  
通常执行内核比传输数据耗时更多，通过将内核执行和数据传输调度到不同的流中，这些操作可以重叠，程序的总运行时间将被缩短。流在CUDA的API调用粒度上可实现流水线或双缓冲技术。  
![image](https://github.com/wustjie/cuda/assets/34996802/10f0e654-c7f6-4cef-aa1a-9cb6a540cc50)  
声明和创建一个显式流：  
cudaStream_t stream;  
cudaStreamCreate(&stream);  
销毁一个流则可以用：  
cudaError_t cudaStreamDestroy(cudaStream_t stream);  

CUDA的API函数一般可以分为同步或异步。具有同步行为的函数会阻塞主机端线程，直到它们完成。具有异步行为的函数被调用后，会立即将控制权归还给主机。  
异步函数和流是在CUDA中构建网格级并发的两个基本支柱。  

所有的CUDA操作（包括内核和数据传输）都在一个流中显式或隐式地运行。流分为两种类型：  
·隐式声明的流（空流）  
·显式声明的流（非空流）  
非空流可以被显式地创建和管理。如果想要重叠不同的CUDA操作，必须使用非空流。  

使用下面的方法可以声明和创建一个显式流：  
cudaStream_t stream;  
cudaStreamCreate(&stream);  
要销毁一个流则可以使用下面的函数  
cudaError_t cudaStreamDestroy(cudaStream_t stream);  

内存加载流操作：  
显式流中的操作必须是异步的，cudaMemcpy函数是一种同步操作，必须使用它的异步版本才能在显式流中进行数据拷贝  
cudaError_t cudaMemcpyAsync(void* dst, const void* src, size_t count, cudaMemcpyKind kind, cudaStream_t stream = 0);  
要执行异步的数据传输，那么就必须在host上使用固定内存，因为这样才能确保其在CPU内存中的物理地址在应用程序的整个生命周期内都不会被改变。  
可以使用下面的两个函数在host上分配固定内存：  
cudaError_t cudaMallocHost(void **ptr, size_t size);  
cudaError_t cudaHostAlloc(void **pHost, size_t size, unsigned int flags);  

内核启动流操作：  
在非空流中启动内核的时候，必须在内核执行配置中提供一个流标识符作为第4个参数（第3个参数为共享内存的大小，如果没有分配可以设置为0）：  
kernel_name<<<grid, block, sharedMemSize, stream>>>(...);

显式流的所有操作都是异步的，可以在host代码中调用下面两个函数去检查流中的所有操作是否完成：  
cudaError_t cudaStreamSynchronize(cudaStream_t stream);  
cudaError_t cudaStreamQuery(cudaStream_t stream);  
cudaStreamSynchronize函数会强制阻塞host直到指定流中的所有操作都已经执行完成；cudaStreamQuery函数则不会阻塞host，如果指定流中的所有操作都已完成，  
它会返回cudaSuccess，否则返回cudaErrorNotReady。  

#CUDA事件  
一个CUDA事件是CUDA流中的一个标记点，用来检查正在执行的流操作是否已经到达了该点。使用事件可以用来执行以下两个基本任务：  
·同步流的执行操作  
·监控device的进展  
声明和创建一个事件的方式如下：  
cudaEvent_t event;  
cudaError_t cudaEventCreate(cudaEvent_t* event);  
调用下面的函数可以销毁一个事件  
cudaError_t cudaEventDestroy(cudaEvent_t event);  
一个事件可以使用如下函数进入CUDA流的操作队列中  
cudaError_t cudaEventRecord(cudaEvent_t event, cudaStream_t stream = 0);  
下面的函数会在host中阻塞式地等待一个事件完成  
cudaError_t cudaEventSynchronize(cudaEvent_t event);  
与流类似的，也可以非阻塞式地去查询事件的完成情况  
cudaError_t cudaEventQuery(cudaEvent_t event);  
如果想知道两个事件之间的操作所耗费的时间，可以调用  
cudaError_t cudaEventElapsedTime(float* ms, cudaEvent_t start, cudaEvent_t stop);  

计算两个事件之间的时间：  
cudaEvent_t start, stop;  
cudaEventCreate(&start);  
cudaEventCreate(&stop);  
cudaEventRecord(start);  
VectorAddGPU<<<block_per_grid, thread_per_block>>>(da, db, dc, size);  
cudaEventRecord(stop);  
cudaEventSynchronize(stop);  
float elapsed_time;  
cudaEventElapsedTime(&elapsed_time, start, stop);  
std::cout << "Elapsed time: " << elapsed_time << " ms." << std::endl;  
cudaEventDestroy(start);  
cudaEventDestroy(stop);  
启动和结束不必在一个流中  

#流同步  
CUDA包括两种类型的host-device同步：显示同步和隐式同步。  
许多与内存相关的操作都带有隐式同步行为，它会使得host应用程序阻塞，比如cudaMemcpy，cudaMallocHost，cudaMalloc，一级缓存/共享内存配置的修改等  

CUDA提供了几种显示同步的方法：  
使用cudaDeviceSynchronize函数同步device  
使用cudaStreamSynchronize函数同步流  
使用cudaEventSynchronize函数同步流中的事件  
除此之外，CUDA还提供了下面的函数使用事件进行跨流同步：  
cudaError_t cudaStreamWaitEvent(cudaStream_t stream, cudaEvent_t event);  
该函数可以使指定的流等待指定的事件，如果是不同的流那么这个函数就是执行跨流同步功能。
